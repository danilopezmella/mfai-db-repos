TITLE: Handling API Errors
DESCRIPTION: This snippet demonstrates how to handle API errors raised by the model service using a try-except block. It attempts to generate content with an invalid model name and catches the APIError, printing the error code and message.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_85

LANGUAGE: python
CODE:
```
from google.genai import errors

try:
  client.models.generate_content(
      model="invalid-model-name",
      contents="What is your name?",
  )
except errors.APIError as e:
  print(e.code) # 404
  print(e.message)
```

----------------------------------------

TITLE: Streaming Text Content with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to stream text content using the Gemini API. It initializes a client and then iterates through the chunks of the generated content, printing each chunk to the console.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_37

LANGUAGE: python
CODE:
```
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Generating Content with Gemini Model in Python
DESCRIPTION: This code snippet demonstrates how to generate content using a Gemini model. It initializes a client, specifies the model name and content, and then prints the generated text.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_60

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents='Summarize the pdfs',
        config=types.GenerateContentConfig(
            cached_content=cached_content.name,
        ),
    )
    print(response.text)
```

----------------------------------------

TITLE: Generating content with text input
DESCRIPTION: Generates content using the `generate_content` method with a text prompt. The response includes the generated text, which is then printed to the console.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_9

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001', contents='Why is the sky blue?'
)
print(response.text)
```

----------------------------------------

TITLE: Streaming Chat Messages in Python
DESCRIPTION: This code demonstrates how to stream chat messages from a model. It creates a chat session and iterates through the message stream, printing each chunk of text as it arrives. This is useful for real-time applications where immediate feedback is needed.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_52

LANGUAGE: Python
CODE:
```
chat = client.chats.create(model='gemini-2.0-flash-001')
for chunk in chat.send_message_stream('tell me a story'):
    print(chunk.text)
```

----------------------------------------

TITLE: Installing google-genai package
DESCRIPTION: This command installs the google-genai package using pip, allowing you to use the Google Gen AI SDK in your Python projects. It fetches the latest version of the package from PyPI and installs it along with its dependencies.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_0

LANGUAGE: shell
CODE:
```
pip install google-genai
```

----------------------------------------

TITLE: Streaming Text Content
DESCRIPTION: This example demonstrates how to stream text content from the Gemini API. It iterates through the chunks of the response and prints the text.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_37

LANGUAGE: python
CODE:
```
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Configuring System Instructions and Other Settings
DESCRIPTION: This snippet demonstrates how to configure the Gemini model's behavior using the `GenerateContentConfig` object, including setting the system instruction, maximum output tokens, and temperature.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_19

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='high',
    config=types.GenerateContentConfig(
        system_instruction='I say high, you say low',
        max_output_tokens=3,
        temperature=0.3,
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Creating a Chat Session and Sending a Message in Python
DESCRIPTION: This code snippet shows how to create a chat session with a specified model and send a message to it. It initializes a chat object, sends a message, and prints the response text. The example uses the 'gemini-2.0-flash-001' model.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_51

LANGUAGE: Python
CODE:
```
chat = client.chats.create(model='gemini-2.0-flash-001')
response = chat.send_message('tell me a story')
print(response.text)
```

----------------------------------------

TITLE: Asynchronous Content Generation with Gemini API in Python
DESCRIPTION: This code snippet demonstrates asynchronous content generation using the Gemini API. It uses the `client.aio` interface to call the `generate_content` method asynchronously.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_40

LANGUAGE: python
CODE:
```
response = await client.aio.models.generate_content(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
)

print(response.text)
```

----------------------------------------

TITLE: Invoking Function and Passing Response
DESCRIPTION: This code snippet demonstrates how to invoke a function after receiving the function call part from the model, get the function response, and pass it back to the model. It handles potential exceptions during function execution and constructs the function response part.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_30

LANGUAGE: python
CODE:
```
user_prompt_content = types.Content(
    role='user',
    parts=[types.Part.from_text(text='What is the weather like in Boston?')],
)
function_call_part = response.function_calls[0]
function_call_content = response.candidates[0].content


try:
    function_result = get_current_weather(
        **function_call_part.function_call.args
    )
    function_response = {'result': function_result}
except (
    Exception
) as e:  # instead of raising the exception, you can let the model handle it
    function_response = {'error': str(e)}


function_response_part = types.Part.from_function_response(
    name=function_call_part.name,
    response=function_response,
)
function_response_content = types.Content(
    role='tool', parts=[function_response_part]
)

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=[
        user_prompt_content,
        function_call_content,
        function_response_content,
    ],
    config=types.GenerateContentConfig(
        tools=[tool],
    ),
)

print(response.text)
```

----------------------------------------

TITLE: Setting GOOGLE_API_KEY environment variable
DESCRIPTION: Sets the GOOGLE_API_KEY environment variable for authenticating with the Gemini Developer API. This allows the client to be initialized without explicitly passing the API key in the code.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_4

LANGUAGE: bash
CODE:
```
export GOOGLE_API_KEY='your-api-key'
```

----------------------------------------

TITLE: Counting Tokens
DESCRIPTION: This example demonstrates how to count the number of tokens in a given content using the Gemini API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_42

LANGUAGE: python
CODE:
```
response = client.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Generating Images with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to generate images using the Gemini API. It calls the `generate_images` method with a prompt and configuration, then displays the generated image.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_47

LANGUAGE: python
CODE:
```
# Generate Image
response1 = client.models.generate_images(
    model='imagen-3.0-generate-002',
    prompt='An umbrella in the foreground, and a rainy night sky in the background',
    config=types.GenerateImagesConfig(
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response1.generated_images[0].image.show()
```

----------------------------------------

TITLE: Streaming Chat Message with GenAI
DESCRIPTION: This code snippet demonstrates how to create a chat session and stream a message using the GenAI client. It initializes a chat with the 'gemini-2.0-flash-001' model and iterates through the stream of chunks, printing the text from each chunk.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_52

LANGUAGE: python
CODE:
```
chat = client.chats.create(model='gemini-2.0-flash-001')
    for chunk in chat.send_message_stream('tell me a story'):
        print(chunk.text, end='')
```

----------------------------------------

TITLE: Manually Declaring and Invoking a Function
DESCRIPTION: This code snippet demonstrates how to manually declare a function and pass it as a tool for function calling. It shows how to define the function's name, description, and parameters using `types.FunctionDeclaration` and `types.Schema`.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_29

LANGUAGE: python
CODE:
```
function = types.FunctionDeclaration(
    name='get_current_weather',
    description='Get the current weather in a given location',
    parameters=types.Schema(
        type='OBJECT',
        properties={
            'location': types.Schema(
                type='STRING',
                description='The city and state, e.g. San Francisco, CA',
            ),
        },
        required=['location'],
    ),
)

tool = types.Tool(function_declarations=[function])

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(tools=[tool]),
)

print(response.function_calls[0])
```

----------------------------------------

TITLE: Generating Content with Pydantic Model Schema
DESCRIPTION: This code snippet demonstrates how to use a Pydantic model as a response schema for the Gemini model. It defines a `CountryInfo` model and passes it as the `response_schema` to the `generate_content` method, specifying that the response should conform to the structure defined by the model.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_33

LANGUAGE: python
CODE:
```
from pydantic import BaseModel


class CountryInfo(BaseModel):
    name: str
    population: int
    capital: str
    continent: str
    gdp: int
    official_language: str
    total_area_sq_mi: int


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema=CountryInfo,
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Configuring Safety Settings
DESCRIPTION: This code snippet demonstrates how to configure safety settings to filter content based on categories and thresholds. It sets a safety setting to block only high levels of hate speech.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_25

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Say something bad.',
    config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(
                category='HARM_CATEGORY_HATE_SPEECH',
                threshold='BLOCK_ONLY_HIGH',
            )
        ]
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Setting System Instructions and Config in Python
DESCRIPTION: This snippet demonstrates how to set system instructions, max output tokens, and temperature using `types.GenerateContentConfig` to influence the model's output.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_19

LANGUAGE: python
CODE:
```
response = client.models.generate_content(\n        model='gemini-2.0-flash-001',\n        contents='high',\n        config=types.GenerateContentConfig(\n            system_instruction='I say high, you say low',\n            max_output_tokens=3,\n            temperature=0.3,\n        ),\n    )\n    print(response.text)
```

----------------------------------------

TITLE: Pydantic Model Schema Support (Python)
DESCRIPTION: This code demonstrates how to provide a schema as a Pydantic model to the `generate_content` method. It defines a `CountryInfo` model with fields like name, population, and capital, and then passes it as the `response_schema` in the configuration.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_33

LANGUAGE: python
CODE:
```
from pydantic import BaseModel


class CountryInfo(BaseModel):
    name: str
    population: int
    capital: str
    continent: str
    gdp: int
    official_language: str
    total_area_sq_mi: int


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema=CountryInfo,
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Creating an Asynchronous Chat Session and Sending a Message in Python
DESCRIPTION: This code shows how to create an asynchronous chat session and send a message. It uses the `aio` client for asynchronous operations. The code initializes a chat object, sends a message, and prints the response text using `await`.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_53

LANGUAGE: Python
CODE:
```
chat = client.aio.chats.create(model='gemini-2.0-flash-001')
response = await chat.send_message('tell me a story')
print(response.text)
```

----------------------------------------

TITLE: Set Automatic Function Call Turns (Python)
DESCRIPTION: This snippet shows how to configure the number of automatic function call turns by setting the `maximum_remote_calls` parameter in the `automatic_function_calling` configuration.  The example sets it to 2, allowing for one turn of automatic function calling.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_32

LANGUAGE: python
CODE:
```
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            maximum_remote_calls=2
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)
```

----------------------------------------

TITLE: Generating Videos with Veo Model in Python
DESCRIPTION: This code demonstrates how to generate videos using the Veo model. It initializes a video generation operation, sets the model, prompt, and configuration parameters such as the number of videos, frames per second, duration, and prompt enhancement. It then polls the operation until it is complete and displays the generated video.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_50

LANGUAGE: Python
CODE:
```
operation = client.models.generate_videos(
    model='veo-2.0-generate-001',
    prompt='A neon hologram of a cat driving at top speed',
    config=types.GenerateVideosConfig(
        number_of_videos=1,
        fps=24,
        duration_seconds=5,
        enhance_prompt=True,
    ),
)

# Poll operation
while not operation.done:
    time.sleep(20)
    operation = client.operations.get(operation)

video = operation.result.generated_videos[0].video
video.show()
```

----------------------------------------

TITLE: Generating Content with Text
DESCRIPTION: This code generates content using the `generate_content` method. It specifies the model to use ('gemini-2.0-flash-001') and the content to generate from ('Why is the sky blue?'). The response text is then printed to the console.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_9

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001', contents='Why is the sky blue?'
)
print(response.text)
```

----------------------------------------

TITLE: Generating Content with Function Response
DESCRIPTION: This code snippet demonstrates how to generate content using a function response with the Gemini model. It creates parts for the function response and combines them into a content object, which is then used in the generate_content call.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_30

LANGUAGE: python
CODE:
```
function_response_part = types.Part.from_function_response(
        name=function_call_part.name,
        response=function_response,
    )
    function_response_content = types.Content(
        role='tool', parts=[function_response_part]
    )

    response = client.models.generate_content(
        model='gemini-2.0-flash-001',
        contents=[
            user_prompt_content,
            function_call_content,
            function_response_content,
        ],
        config=types.GenerateContentConfig(
            tools=[tool],
        ),
    )

    print(response.text)
```

----------------------------------------

TITLE: Generating Videos with GenAI
DESCRIPTION: This code snippet demonstrates how to generate a video using the GenAI client and the 'veo-2.0-generate-001' model. It creates an operation to generate the video based on a prompt and configuration, polls the operation until it's complete, and then displays the generated video.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_50

LANGUAGE: python
CODE:
```
operation = client.models.generate_videos(
        model='veo-2.0-generate-001',
        prompt='A neon hologram of a cat driving at top speed',
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            fps=24,
            duration_seconds=5,
            enhance_prompt=True,
        ),
    )

    # Poll operation
    while not operation.done:
        time.sleep(20)
        operation = client.operations.get(operation)

    video = operation.result.generated_videos[0].video
    video.show()
```

----------------------------------------

TITLE: Sending Async Chat Message with GenAI
DESCRIPTION: This code snippet demonstrates how to create an asynchronous chat session and send a message using the GenAI client. It initializes a chat with the 'gemini-2.0-flash-001' model, sends a message asynchronously, and prints the response text.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_53

LANGUAGE: python
CODE:
```
chat = client.aio.chats.create(model='gemini-2.0-flash-001')
    response = await chat.send_message('tell me a story')
    print(response.text)
```

----------------------------------------

TITLE: Handling API Errors in Python
DESCRIPTION: This code snippet demonstrates how to handle API errors raised by the GenAI client, specifically when generating content with an invalid model name.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_85

LANGUAGE: python
CODE:
```
try:
        client.models.generate_content(
            model="invalid-model-name",
            contents="What is your name?",
        )
    except errors.APIError as e:
        print(e.code) # 404
        print(e.message)
```

----------------------------------------

TITLE: Generating Content with Uploaded File
DESCRIPTION: This code uploads a file and then generates content using the uploaded file as part of the input. It uses the `client.files.upload` method to upload the file, then passes the file object within the `contents` list to `generate_content`. This functionality is specific to the Gemini Developer API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_11

LANGUAGE: python
CODE:
```
file = client.files.upload(file='a11.txt')
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=['Could you summarize this file?', file]
)
print(response.text)
```

----------------------------------------

TITLE: Listing Available Models
DESCRIPTION: This code snippet demonstrates how to list the available models using the client.models.list() method. It iterates through the models and prints each model object.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_21

LANGUAGE: python
CODE:
```
for model in client.models.list():
    print(model)
```

----------------------------------------

TITLE: Initializing Gemini Developer API Client
DESCRIPTION: This code initializes a client for the Gemini Developer API.  It requires an API key, which should be obtained from the Google AI Studio.  This client is used to interact with the Gemini models.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_2

LANGUAGE: python
CODE:
```
# Only run this block for Gemini Developer API
client = genai.Client(api_key='GEMINI_API_KEY')
```

----------------------------------------

TITLE: Generating content with file input
DESCRIPTION: Generates content using the `generate_content` method with a file uploaded to the service. The response includes the generated text, which is then printed to the console.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_11

LANGUAGE: python
CODE:
```
file = client.files.upload(file='a11.txt')
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=['Could you summarize this file?', file]
)
print(response.text)
```

----------------------------------------

TITLE: Automatic Function Calling
DESCRIPTION: This code snippet demonstrates automatic function calling, where a Python function is passed directly to the model and automatically invoked. The function returns weather information based on the provided location.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_26

LANGUAGE: python
CODE:
```
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return 'sunny'


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(tools=[get_current_weather]),
)

print(response.text)
```

----------------------------------------

TITLE: Creating a Gemini Developer API client
DESCRIPTION: Creates a client instance for the Gemini Developer API, authenticating with an API key.  The API key is required for accessing the Gemini models.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_2

LANGUAGE: python
CODE:
```
client = genai.Client(api_key='GEMINI_API_KEY')
```

----------------------------------------

TITLE: Dictionary Schema Support (Python)
DESCRIPTION: This code demonstrates how to provide a schema as a dictionary to the `generate_content` method. It defines a dictionary with `required` and `properties` keys, specifying the schema for the response.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_34

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema={
            'required': [
                'name',
                'population',
                'capital',
                'continent',
                'gdp',
                'official_language',
                'total_area_sq_mi',
            ],
            'properties': {
                'name': {'type': 'STRING'},
                'population': {'type': 'INTEGER'},
                'capital': {'type': 'STRING'},
                'continent': {'type': 'STRING'},
                'gdp': {'type': 'INTEGER'},
                'official_language': {'type': 'STRING'},
                'total_area_sq_mi': {'type': 'INTEGER'},
            },
            'type': 'OBJECT',
        },
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Counting Tokens with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to count tokens in a given text using the Gemini API. It calls the `count_tokens` method and prints the response.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_42

LANGUAGE: python
CODE:
```
response = client.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Initializing Client with Environment Variables
DESCRIPTION: This code initializes a client using environment variables for configuration. It automatically detects and uses the appropriate credentials and settings based on the environment variables set for either the Gemini Developer API or Vertex AI.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_6

LANGUAGE: python
CODE:
```
client = genai.Client()
```

----------------------------------------

TITLE: Invoking Function and Passing Response
DESCRIPTION: This snippet shows how to invoke a function after receiving a function call part from the model and pass the function response back to the model.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_29

LANGUAGE: python
CODE:
```
user_prompt_content = types.Content(
    role='user',
    parts=[types.Part.from_text(text='What is the weather like in Boston?')],
)
function_call_part = response.function_calls[0]
function_call_content = response.candidates[0].content


try:
    function_result = get_current_weather(
        **function_call_part.function_call.args
    )
    function_response = {'result': function_result}
except (
    Exception
) as e:  # instead of raising the exception, you can let the model handle it
    function_response = {'error': str(e)}
```

----------------------------------------

TITLE: Streaming Asynchronous Chat Messages in Python
DESCRIPTION: This code demonstrates how to stream chat messages asynchronously. It creates an asynchronous chat session and iterates through the message stream, printing each chunk of text as it arrives. This is useful for non-blocking applications.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_54

LANGUAGE: Python
CODE:
```
chat = client.aio.chats.create(model='gemini-2.0-flash-001')
async for chunk in await chat.send_message_stream('tell me a story'):
    print(chunk.text)
```

----------------------------------------

TITLE: Creating a Vertex AI API client
DESCRIPTION: Creates a client instance for the Vertex AI API, specifying the project ID and location.  This configuration is necessary for accessing Gemini models deployed on Vertex AI.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_3

LANGUAGE: python
CODE:
```
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)
```

----------------------------------------

TITLE: Using Typed Configuration with Pydantic Types
DESCRIPTION: This snippet shows how to use Pydantic types for configuring the Gemini model, allowing for type checking and validation of the configuration parameters.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_20

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents=types.Part.from_text(text='Why is the sky blue?'),
    config=types.GenerateContentConfig(
        temperature=0,
        top_p=0.95,
        top_k=20,
        candidate_count=1,
        seed=5,
        max_output_tokens=100,
        stop_sequences=['STOP!'],
        presence_penalty=0.0,
        frequency_penalty=0.0,
    ),
)

print(response.text)
```

----------------------------------------

TITLE: Asynchronous Token Counting with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to asynchronously count tokens in a given text using the Gemini API. It uses the `client.aio` interface to call the `count_tokens` method asynchronously.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_44

LANGUAGE: python
CODE:
```
response = await client.aio.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Using Typed Config with Pydantic Types in Python
DESCRIPTION: This snippet shows how to use Pydantic types for parameters, specifically `types.GenerateContentConfig`, when calling API methods.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_20

LANGUAGE: python
CODE:
```
response = client.models.generate_content(\n        model='gemini-2.0-flash-001',\n        contents=types.Part.from_text(text='Why is the sky blue?'),\n        config=types.GenerateContentConfig(\n            temperature=0,\n
```

----------------------------------------

TITLE: Asynchronous Content Generation
DESCRIPTION: This example demonstrates how to generate content asynchronously using the Gemini API's aio client. It uses the await keyword to wait for the response.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_40

LANGUAGE: python
CODE:
```
response = await client.aio.models.generate_content(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
)

print(response.text)
```

----------------------------------------

TITLE: Generating Content with JSON Schema
DESCRIPTION: This code snippet demonstrates how to use a JSON schema as a response schema for the Gemini model. It defines a JSON schema with required properties and their types, and passes it as the `response_schema` to the `generate_content` method.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_34

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Give me information for the United States.',
    config=types.GenerateContentConfig(
        response_mime_type='application/json',
        response_schema={
            'required': [
                'name',
                'population',
                'capital',
                'continent',
                'gdp',
                'official_language',
                'total_area_sq_mi',
            ],
            'properties': {
                'name': {'type': 'STRING'},
                'population': {'type': 'INTEGER'},
                'capital': {'type': 'STRING'},
                'continent': {'type': 'STRING'},
                'gdp': {'type': 'INTEGER'},
                'official_language': {'type': 'STRING'},
                'total_area_sq_mi': {'type': 'INTEGER'},
            },
            'type': 'OBJECT',
        },
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Importing genai and types modules
DESCRIPTION: Imports the necessary modules from the google-genai package for interacting with the Gemini API or Vertex AI. These modules provide access to the Client class and type definitions.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_1

LANGUAGE: python
CODE:
```
from google import genai
from google.genai import types
```

----------------------------------------

TITLE: Creating a client with environment variables
DESCRIPTION: Creates a client instance using environment variables for configuration. This simplifies client initialization by avoiding hardcoding API keys or project details in the code.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_6

LANGUAGE: python
CODE:
```
client = genai.Client()
```

----------------------------------------

TITLE: Asynchronous Token Counting
DESCRIPTION: This example demonstrates how to count tokens asynchronously using the Gemini API's aio client.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_44

LANGUAGE: python
CODE:
```
response = await client.aio.models.count_tokens(
    model='gemini-2.0-flash-001',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Listing Base Models
DESCRIPTION: This snippet demonstrates how to list the available base models using the `client.models.list()` method.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_21

LANGUAGE: python
CODE:
```
for model in client.models.list():
    print(model)
```

----------------------------------------

TITLE: Initializing Vertex AI API Client
DESCRIPTION: This code initializes a client for the Vertex AI API. It requires a project ID and location, which should be configured in your Google Cloud project. This client is used to interact with the Gemini models deployed on Vertex AI.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_3

LANGUAGE: python
CODE:
```
# Only run this block for Vertex AI API
client = genai.Client(
    vertexai=True, project='your-project-id', location='us-central1'
)
```

----------------------------------------

TITLE: Asynchronous Model Listing
DESCRIPTION: This code snippet demonstrates how to asynchronously list available models using the GenAI client's `aio` interface. It iterates through the models and prints each one.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_23

LANGUAGE: python
CODE:
```
async for job in await client.aio.models.list():
    print(job)
```

----------------------------------------

TITLE: Setting Vertex AI environment variables
DESCRIPTION: Sets the environment variables required for authenticating with the Gemini API on Vertex AI. These variables specify that Vertex AI should be used, along with the project ID and location.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_5

LANGUAGE: bash
CODE:
```
export GOOGLE_GENAI_USE_VERTEXAI=true
export GOOGLE_CLOUD_PROJECT='your-project-id'
export GOOGLE_CLOUD_LOCATION='us-central1'
```

----------------------------------------

TITLE: Asynchronous Streaming with Gemini API in Python
DESCRIPTION: This code snippet demonstrates asynchronous streaming using the Gemini API. It uses the `client.aio` interface to call the `generate_content_stream` method asynchronously and iterates through the chunks.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_41

LANGUAGE: python
CODE:
```
async for chunk in await client.aio.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Generating Content with Response Schema
DESCRIPTION: This example demonstrates how to generate content using the Gemini API and specify a response schema using an Enum. The response_mime_type is set to 'text/x.enum'.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_36

LANGUAGE: python
CODE:
```
class InstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'

response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What instrument plays multiple notes at once?',
    config={
        'response_mime_type': 'application/json',
        'response_schema': InstrumentEnum,
    },
)
print(response.text)
```

----------------------------------------

TITLE: Installing google-genai package with pip
DESCRIPTION: Installs the google-genai package using pip, enabling the use of Google's generative AI models in Python applications.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_0

LANGUAGE: sh
CODE:
```
pip install google-genai
```

----------------------------------------

TITLE: Enum Response Schema - Text (Python)
DESCRIPTION: This code demonstrates how to use an Enum as a response schema with `response_mime_type` set to `text/x.enum`. The model will return one of the enum values as a string.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_35

LANGUAGE: python
CODE:
```
class InstrumentEnum(Enum):
  PERCUSSION = 'Percussion'
  STRING = 'String'
  WOODWIND = 'Woodwind'
  BRASS = 'Brass'
  KEYBOARD = 'Keyboard'

response = client.models.generate_content(
      model='gemini-2.0-flash-001',
      contents='What instrument plays multiple notes at once?',
      config={
          'response_mime_type': 'text/x.enum',
          'response_schema': InstrumentEnum,
      },
  )
print(response.text)
```

----------------------------------------

TITLE: Asynchronous Paged Model Listing
DESCRIPTION: This code snippet showcases asynchronous paged listing of models, configuring the page size and iterating through pages. It demonstrates accessing page size, elements, and navigating to the next page.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_24

LANGUAGE: python
CODE:
```
async_pager = await client.aio.models.list(config={'page_size': 10})
print(async_pager.page_size)
print(async_pager[0])
await async_pager.next_page()
print(async_pager[0])
```

----------------------------------------

TITLE: Listing Models with Pagination
DESCRIPTION: This example shows how to list models with pagination using the client.models.list() method with a specified page size. It demonstrates accessing the page size, retrieving the first element, and navigating to the next page.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_22

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: Creating User Content
DESCRIPTION: This code demonstrates how the SDK converts a simple string input into a `types.UserContent` object with a text part. This shows the implicit conversion that occurs when a string is provided as the `contents` argument to `generate_content`.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_13

LANGUAGE: python
CODE:
```
contents='Why is the sky blue?'
```

----------------------------------------

TITLE: Asynchronously Listing Gemini Models in Python
DESCRIPTION: This code snippet demonstrates how to asynchronously list Gemini models. It uses the `aio` client to retrieve models and print their details.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_69

LANGUAGE: python
CODE:
```
async for job in await client.aio.models.list(config={'page_size': 10, 'query_base': False}}):
        print(job)
```

----------------------------------------

TITLE: Providing a List of Strings as Content
DESCRIPTION: This snippet shows how a list of strings is converted into a single `types.UserContent` object with multiple text parts when passed to the Gemini API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_14

LANGUAGE: python
CODE:
```
contents=['Why is the sky blue?', 'Why is the cloud white?']
```

LANGUAGE: python
CODE:
```
[
  types.UserContent(
    parts=[
      types.Part.from_text(text='Why is the sky blue?'),
      types.Part.from_text(text='Why is the cloud white?'),
    ]
  )
]
```

----------------------------------------

TITLE: Listing Base Models with Paging
DESCRIPTION: This snippet demonstrates how to list base models with pagination, allowing you to control the number of results returned per page.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_22

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: Setting Vertex AI environment variables
DESCRIPTION: These commands set the environment variables required to use the Gemini API in Vertex AI. `GOOGLE_GENAI_USE_VERTEXAI` enables Vertex AI, `GOOGLE_CLOUD_PROJECT` specifies your Google Cloud project ID, and `GOOGLE_CLOUD_LOCATION` sets the region.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_5

LANGUAGE: bash
CODE:
```
export GOOGLE_GENAI_USE_VERTEXAI=true
export GOOGLE_CLOUD_PROJECT='your-project-id'
export GOOGLE_CLOUD_LOCATION='us-central1'
```

----------------------------------------

TITLE: Non-Function Call Part to UserContent Conversion in Python
DESCRIPTION: This snippet demonstrates how a non-function call part (in this case, an image URI) is converted into a `types.UserContent` object. The `role` field is set to `user`.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_17

LANGUAGE: python
CODE:
```
contents = types.Part.from_uri(\n    file_uri: 'gs://generativeai-downloads/images/scones.jpg',\n    mime_type: 'image/jpeg',\n    )
```

LANGUAGE: python
CODE:
```
[\n    types.UserContent(parts=[\n        types.Part.from_uri(\n        file_uri: 'gs://generativeai-downloads/images/scones.jpg',\n        mime_type: 'image/jpeg',\n        )\n    ])\n]
```

----------------------------------------

TITLE: Asynchronously Listing Batch Jobs in Python
DESCRIPTION: This code snippet demonstrates how to asynchronously list batch jobs using the GenAI client, iterating through the results using an async for loop.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_82

LANGUAGE: python
CODE:
```
async for job in await client.aio.batches.list(
        config=types.ListBatchJobsConfig(page_size=10)
    ):
        print(job)
```

----------------------------------------

TITLE: Non-Function Call List to UserContent Conversion in Python
DESCRIPTION: This snippet shows how a list of non-function call parts (text and image URI) is converted into a `types.UserContent` object. The `role` field is set to `user`.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_18

LANGUAGE: python
CODE:
```
contents = [\n    types.Part.from_text('What is this image about?'),\n    types.Part.from_uri(\n        file_uri: 'gs://generativeai-downloads/images/scones.jpg',\n        mime_type: 'image/jpeg',\n    )\n]
```

LANGUAGE: python
CODE:
```
[\n    types.UserContent(\n        parts=[\n        types.Part.from_text('What is this image about?'),\n        types.Part.from_uri(\n            file_uri: 'gs://generativeai-downloads/images/scones.jpg',\n            mime_type: 'image/jpeg',\n        )\n        ]\n    )\n]
```

----------------------------------------

TITLE: Listing Batch Prediction Jobs with Pagination
DESCRIPTION: This snippet demonstrates how to use pagination to retrieve batch prediction jobs. It retrieves a page of jobs, prints the page size and the first job, advances to the next page, and prints the first job on the new page.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_81

LANGUAGE: python
CODE:
```
pager = client.batches.list(config=types.ListBatchJobsConfig(page_size=10))
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: Tuning Gemini Model with Vertex AI or Gemini API in Python
DESCRIPTION: This code snippet shows how to tune a Gemini model using either Vertex AI or the Gemini Developer API. It configures the training dataset based on the environment and creates TuningDataset object.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_61

LANGUAGE: python
CODE:
```
if client.vertexai:
        model = 'gemini-2.0-flash-001'
        training_dataset = types.TuningDataset(
            gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',
        )
    else:
        model = 'models/gemini-2.0-flash-001'
        training_dataset = types.TuningDataset(
            examples=[
                types.TuningExample(
                    text_input=f'Input text {i}',
                    output=f'Output text {i}',
                )
                for i in range(5)
            ],
        )
```

----------------------------------------

TITLE: Editing Images with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to edit an image using the Gemini API. It calls the `edit_image` method with a prompt, reference images, and configuration, then displays the edited image. This is only supported in Vertex AI.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_49

LANGUAGE: python
CODE:
```
# Edit the generated image from above
from google.genai.types import RawReferenceImage, MaskReferenceImage

raw_ref_image = RawReferenceImage(
    reference_id=1,
    reference_image=response1.generated_images[0].image,
)

# Model computes a mask of the background
mask_ref_image = MaskReferenceImage(
    reference_id=2,
    config=types.MaskReferenceConfig(
        mask_mode='MASK_MODE_BACKGROUND',
        mask_dilation=0,
    ),
)

response3 = client.models.edit_image(
    model='imagen-3.0-capability-001',
    prompt='Sunlight and clear sky',
    reference_images=[raw_ref_image, mask_ref_image],
    config=types.EditImageConfig(
        edit_mode='EDIT_MODE_INPAINT_INSERTION',
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response3.generated_images[0].image.show()
```

----------------------------------------

TITLE: Listing Batch Prediction Jobs with Pager in Python
DESCRIPTION: This code snippet shows how to list batch prediction jobs using a pager for pagination. It configures the page size.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_80

LANGUAGE: python
CODE:
```
pager = client.batches.list(config=types.ListBatchJobsConfig(page_size=10))
    print(pager.page_size)
```

----------------------------------------

TITLE: Creating a Content Instance
DESCRIPTION: This code creates a `types.Content` instance with a specified role ('user') and a text part. This is the canonical way to provide content to the `generate_content` method, allowing for explicit control over the structure of the input.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_12

LANGUAGE: python
CODE:
```
contents = types.Content(
role='user',
parts=[types.Part.from_text(text='Why is the sky blue?')]
)
```

----------------------------------------

TITLE: Upscaling Image with GenAI
DESCRIPTION: This code snippet demonstrates how to upscale an image using the GenAI client. It takes a generated image as input and upscales it by a specified factor using the 'imagen-3.0-generate-002' model. The upscaled image is then displayed.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_48

LANGUAGE: python
CODE:
```
response2 = client.models.upscale_image(
        model='imagen-3.0-generate-002',
        image=response1.generated_images[0].image,
        upscale_factor='x2',
        config=types.UpscaleImageConfig(
            include_rai_reason=True,
            output_mime_type='image/jpeg',
        ),
    )
    response2.generated_images[0].image.show()
```

----------------------------------------

TITLE: Asynchronously Listing Batch Prediction Jobs
DESCRIPTION: This snippet asynchronously iterates through a list of batch prediction jobs using the client's aio.batches.list method, printing each job. It configures the page size.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_82

LANGUAGE: python
CODE:
```
async for job in await client.aio.batches.list(
    config=types.ListBatchJobsConfig(page_size=10)
):
    print(job)
```

----------------------------------------

TITLE: Asynchronous Streaming
DESCRIPTION: This example demonstrates how to stream content asynchronously using the Gemini API's aio client. It iterates through the chunks of the response and prints the text.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_41

LANGUAGE: python
CODE:
```
async for chunk in await client.aio.models.generate_content_stream(
    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Streaming Image Content from Local File System
DESCRIPTION: This example demonstrates how to stream content from the Gemini API using an image stored in the local file system. It reads the image as bytes and creates a Part object from the bytes data.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_39

LANGUAGE: python
CODE:
```
YOUR_IMAGE_PATH = 'your_image_path'
YOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'
with open(YOUR_IMAGE_PATH, 'rb') as f:
    image_bytes = f.read()

for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),
    ],
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Asynchronously Listing Gemini Models with Pager in Python
DESCRIPTION: This code snippet demonstrates how to asynchronously list Gemini models using a pager. It retrieves models page by page using the `aio` client.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_70

LANGUAGE: python
CODE:
```
async_pager = await client.aio.models.list(config={'page_size': 10, 'query_base': False}})
    print(async_pager.page_size)
    print(async_pager[0])
    await async_pager.next_page()
    print(async_pager[0])
```

----------------------------------------

TITLE: Uploading Files with GenAI
DESCRIPTION: This code snippet demonstrates how to upload files using the GenAI client. It uploads two PDF files and prints the file information for each.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_55

LANGUAGE: python
CODE:
```
file1 = client.files.upload(file='2312.11805v3.pdf')
    file2 = client.files.upload(file='2403.05530.pdf')

    print(file1)
    print(file2)
```

----------------------------------------

TITLE: Listing Tuning Jobs
DESCRIPTION: This snippet iterates through a list of tuning jobs using the client's tunings.list method, printing each job. It configures the page size.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_73

LANGUAGE: python
CODE:
```
for job in client.tunings.list(config={'page_size': 10}):
    print(job)
```

----------------------------------------

TITLE: Generating Content with Enum Response Schema
DESCRIPTION: This code snippet demonstrates how to use an Enum as a response schema for the Gemini model. It defines an `InstrumentEnum` and sets response_mime_type to 'text/x.enum' to return one of those enum values as the response.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_35

LANGUAGE: python
CODE:
```
from enum import Enum

class InstrumentEnum(Enum):
    PERCUSSION = 'Percussion'
    STRING = 'String'
    WOODWIND = 'Woodwind'
    BRASS = 'Brass'
    KEYBOARD = 'Keyboard'
```

----------------------------------------

TITLE: Getting File Information from Gemini API in Python
DESCRIPTION: This code shows how to retrieve file information from the Gemini API. It first uploads a file, then retrieves its information using the file's name.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_57

LANGUAGE: Python
CODE:
```
file1 = client.files.upload(file='2312.11805v3.pdf')
file_info = client.files.get(name=file1.name)
```

----------------------------------------

TITLE: Updating a Tuned Gemini Model in Python
DESCRIPTION: This code snippet shows how to update a tuned Gemini model's configuration, such as display name and description.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_71

LANGUAGE: python
CODE:
```
model = pager[0]

    model = client.models.update(
        model=model.name,
        config=types.UpdateModelConfig(
            display_name='my tuned model', description='my tuned model description'
        ),
    )

    print(model)
```

----------------------------------------

TITLE: Getting Cached Content with GenAI
DESCRIPTION: This code snippet demonstrates how to retrieve cached content using the GenAI client. It retrieves a cache entry using its name.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_59

LANGUAGE: python
CODE:
```
cached_content = client.caches.get(name=cached_content.name)
```

----------------------------------------

TITLE: Configuring Safety Settings
DESCRIPTION: This code snippet demonstrates how to configure safety settings to filter potentially harmful content. It sets a threshold to block only high levels of hate speech.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_25

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='Say something bad.',
    config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(
                category='HARM_CATEGORY_HATE_SPEECH',
                threshold='BLOCK_ONLY_HIGH',
            )
        ]
    ),
)
print(response.text)
```

----------------------------------------

TITLE: Automatic Function Calling
DESCRIPTION: This example demonstrates automatic function calling, where a Python function is passed directly as a tool. The model automatically calls the function and responds with the result.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_26

LANGUAGE: python
CODE:
```
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return 'sunny'


response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
    ),
)

print(response.text)
```

----------------------------------------

TITLE: Getting Cached Content in Python
DESCRIPTION: This code shows how to retrieve cached content using the Gemini API. It retrieves the cached content using its name.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_60

LANGUAGE: Python
CODE:
```
cached_content = client.caches.get(name=cached_content.name)
```

----------------------------------------

TITLE: Creating a Vertex AI client with API version
DESCRIPTION: Creates a Vertex AI client and sets the API version using http_options. This allows selecting a specific API version, such as 'v1', for accessing stable API endpoints.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_7

LANGUAGE: python
CODE:
```
client = genai.Client(
    vertexai=True,
    project='your-project-id',
    location='us-central1',
    http_options=types.HttpOptions(api_version='v1')
)
```

----------------------------------------

TITLE: Starting a Gemini Model Tuning Job in Python
DESCRIPTION: This code snippet demonstrates how to start a tuning job for a Gemini model. It configures the tuning job with a base model, training dataset, and configuration, then prints the tuning job details.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_62

LANGUAGE: python
CODE:
```
tuning_job = client.tunings.tune(
        base_model=model,
        training_dataset=training_dataset,
        config=types.CreateTuningJobConfig(
            epoch_count=1, tuned_model_display_name='test_dataset_examples model'
        ),
    )
    print(tuning_job)
```

----------------------------------------

TITLE: Creating a Gemini API client with API version
DESCRIPTION: Creates a Gemini Developer API client and sets the API version using http_options. This allows selecting a specific API version, such as 'v1alpha', for accessing preview API endpoints.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_8

LANGUAGE: python
CODE:
```
client = genai.Client(
    api_key='GEMINI_API_KEY',
    http_options=types.HttpOptions(api_version='v1alpha')
)
```

----------------------------------------

TITLE: Embedding Multiple Contents with Config
DESCRIPTION: This example demonstrates how to embed multiple contents with a specific configuration using the Gemini API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_46

LANGUAGE: python
CODE:
```
# multiple contents with config
response = client.models.embed_content(
    model='text-embedding-004',
    contents=['why is the sky blue?', 'What is your age?'],
    config=types.EmbedContentConfig(output_dimensionality=10),
)

print(response)
```

----------------------------------------

TITLE: Creating a Tuning Job in Python
DESCRIPTION: This code creates a tuning job for a specified base model using a training dataset and configuration. It prints the tuning job information.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_63

LANGUAGE: Python
CODE:
```
tuning_job = client.tunings.tune(
    base_model=model,
    training_dataset=training_dataset,
    config=types.CreateTuningJobConfig(
        epoch_count=1, tuned_model_display_name='test_dataset_examples model'
    ),
)
print(tuning_job)
```

----------------------------------------

TITLE: Initializing Gemini API Client with API Version
DESCRIPTION: This code initializes a Gemini Developer API client and sets the API version to 'v1alpha' using `http_options`. This allows you to use a specific version of the API, such as a preview release, instead of the default beta endpoints.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_8

LANGUAGE: python
CODE:
```
# Only run this block for Gemini Developer API
client = genai.Client(
    api_key='GEMINI_API_KEY',
    http_options=types.HttpOptions(api_version='v1alpha')
)
```

----------------------------------------

TITLE: Monitoring Tuning Job Status in Python
DESCRIPTION: This code snippet demonstrates how to monitor the status of a tuning job. It retrieves the job status, checks if it's in a running state, and waits until the job completes.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_64

LANGUAGE: python
CODE:
```
import time

    running_states = set(
        [
            'JOB_STATE_PENDING',
            'JOB_STATE_RUNNING',
        ]
    )

    while tuning_job.state in running_states:
        print(tuning_job.state)
        tuning_job = client.tunings.get(name=tuning_job.name)
        time.sleep(10)
```

----------------------------------------

TITLE: Disable Automatic Function Calling in ANY Mode (Python)
DESCRIPTION: This code snippet demonstrates how to disable automatic function calling when the function calling mode is set to `ANY`. It defines a function `get_current_weather` and passes it as a tool to the `generate_content` method, while also setting `disable=True` in the `automatic_function_calling` configuration.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_31

LANGUAGE: python
CODE:
```
def get_current_weather(location: str) -> str:
    """Returns the current weather.

    Args:
      location: The city and state, e.g. San Francisco, CA
    """
    return "sunny"

response = client.models.generate_content(
    model="gemini-2.0-flash-001",
    contents="What is the weather like in Boston?",
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(mode='ANY')
        ),
    ),
)
```

----------------------------------------

TITLE: Embedding Content
DESCRIPTION: This example demonstrates how to embed content using the Gemini API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_45

LANGUAGE: python
CODE:
```
response = client.models.embed_content(
    model='text-embedding-004',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Using a Tuned Gemini Model in Python
DESCRIPTION: This code snippet shows how to use a tuned Gemini model to generate content. It specifies the tuned model endpoint and content, then prints the generated text.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_65

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
        model=tuning_job.tuned_model.endpoint,
        contents='why is the sky blue?',
    )

    print(response.text)
```

----------------------------------------

TITLE: Disabling Automatic Function Calling
DESCRIPTION: This code snippet shows how to disable automatic function calling when passing a Python function as a tool. This allows manual handling of function calls.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_27

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
  model='gemini-2.0-flash-001',
  contents='What is the weather like in Boston?',
  config=types.GenerateContentConfig(
    tools=[get_current_weather],
    automatic_function_calling=types.AutomaticFunctionCallingConfig(
      disable=True
    ),
  ),
)
```

----------------------------------------

TITLE: Tuning a Model with Training Data in Python
DESCRIPTION: This code demonstrates how to tune a model using training data. It checks if it's running in Vertex AI to determine the source of the training data (GCS URI or inline examples). It then creates a tuning job with the specified base model, training dataset, and configuration.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_62

LANGUAGE: Python
CODE:
```
if client.vertexai:
    model = 'gemini-2.0-flash-001'
    training_dataset = types.TuningDataset(
        gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',
    )
else:
    model = 'models/gemini-2.0-flash-001'
    training_dataset = types.TuningDataset(
        examples=[
            types.TuningExample(
                text_input=f'Input text {i}',
                output=f'Output text {i}',
            )
            for i in range(5)
        ],
    )
```

----------------------------------------

TITLE: Using a Tuned Model in Python
DESCRIPTION: This code demonstrates how to use a tuned model to generate content. It specifies the tuned model's endpoint and the content to generate.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_66

LANGUAGE: Python
CODE:
```
response = client.models.generate_content(
    model=tuning_job.tuned_model.endpoint,
    contents='why is the sky blue?',
)

print(response.text)
```

----------------------------------------

TITLE: Streaming Image Content from GCS with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to stream image content from Google Cloud Storage using the Gemini API. It creates a Part object from a GCS URI and includes it in the content stream request.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_38

LANGUAGE: python
CODE:
```
for chunk in client.models.generate_content_stream(
    model='gemini-2.0-flash-001',
    contents=[
        'What is this image about?',
        types.Part.from_uri(
            file_uri='gs://generativeai-downloads/images/scones.jpg',
            mime_type='image/jpeg',
        ),
    ],
):
    print(chunk.text, end='')
```

----------------------------------------

TITLE: Embedding Multiple Contents with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to embed multiple contents with configuration using the Gemini API. It calls the `embed_content` method with a list of contents and a configuration object.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_46

LANGUAGE: python
CODE:
```
# multiple contents with config
response = client.models.embed_content(
    model='text-embedding-004',
    contents=['why is the sky blue?', 'What is your age?'],
    config=types.EmbedContentConfig(output_dimensionality=10),
)

print(response)
```

----------------------------------------

TITLE: Listing Tuned Gemini Models in Python
DESCRIPTION: This code snippet shows how to list tuned Gemini models with pagination. It configures the page size and whether to query base models, then iterates through the models and prints their details.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_67

LANGUAGE: python
CODE:
```
for model in client.models.list(config={'page_size': 10, 'query_base': False}}):
        print(model)
```

----------------------------------------

TITLE: Creating Cached Content with GenAI
DESCRIPTION: This code snippet demonstrates how to create cached content using the GenAI client. It creates a cache entry for two PDF files, associating them with a model and a system instruction.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_58

LANGUAGE: python
CODE:
```
if client.vertexai:
        file_uris = [
            'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',
            'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',
        ]
    else:
        file_uris = [file1.uri, file2.uri]

    cached_content = client.caches.create(
        model='gemini-2.0-flash-001',
        config=types.CreateCachedContentConfig(
            contents=[
                types.Content(
                    role='user',
                    parts=[
                        types.Part.from_uri(
                            file_uri=file_uris[0], mime_type='application/pdf'
                        ),
                        types.Part.from_uri(
                            file_uri=file_uris[1],
                            mime_type='application/pdf',
                        ),
                    ],
                )
            ],
            system_instruction='What is the sum of the two pdfs?',
            display_name='test cache',
            ttl='3600s',
        ),
    )
```

----------------------------------------

TITLE: Listing Tuned Models
DESCRIPTION: This snippet iterates through a list of tuned models using the client's models.list method, printing each model. It configures the page size and specifies that only tuned models should be retrieved.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_68

LANGUAGE: python
CODE:
```
for model in client.models.list(config={'page_size': 10, 'query_base': False}):
    print(model)
```

----------------------------------------

TITLE: Creating Cached Content in Python
DESCRIPTION: This code demonstrates how to create cached content using the Gemini API. It creates a cache with references to two PDF files, a system instruction, a display name, and a time-to-live (TTL) value. The code checks if it's running in Vertex AI to determine the file URIs.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_59

LANGUAGE: Python
CODE:
```
if client.vertexai:
    file_uris = [
        'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',
        'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',
    ]
else:
    file_uris = [file1.uri, file2.uri]

cached_content = client.caches.create(
    model='gemini-2.0-flash-001',
    config=types.CreateCachedContentConfig(
        contents=[
            types.Content(
                role='user',
                parts=[
                    types.Part.from_uri(
                        file_uri=file_uris[0], mime_type='application/pdf'
                    ),
                    types.Part.from_uri(
                        file_uri=file_uris[1],
                        mime_type='application/pdf',
                    ),
                ],
            )
        ],
        system_instruction='What is the sum of the two pdfs?',
        display_name='test cache',
        ttl='3600s',
    ),
)
```

----------------------------------------

TITLE: Embedding Content with Gemini API in Python
DESCRIPTION: This code snippet demonstrates how to embed content using the Gemini API. It calls the `embed_content` method and prints the response.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_45

LANGUAGE: python
CODE:
```
response = client.models.embed_content(
    model='text-embedding-004',
    contents='why is the sky blue?',
)
print(response)
```

----------------------------------------

TITLE: Listing Tuned Models with Pagination
DESCRIPTION: This snippet demonstrates how to use pagination to retrieve tuned models. It retrieves a page of models, prints the page size and the first model, advances to the next page, and prints the first model on the new page.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_69

LANGUAGE: python
CODE:
```
pager = client.models.list(config={'page_size': 10, 'query_base': False})
print(pager.page_size)
print(pager[0])
pager.next_page()
print(pager[0])
```

----------------------------------------

TITLE: Deleting File with GenAI
DESCRIPTION: This code snippet demonstrates how to delete a file using the GenAI client. It uploads a PDF file and then deletes it using the file's name.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_57

LANGUAGE: python
CODE:
```
file3 = client.files.upload(file='2312.11805v3.pdf')

    client.files.delete(name=file3.name)
```

----------------------------------------

TITLE: Asynchronously Listing Tuning Jobs in Python
DESCRIPTION: This code snippet demonstrates how to asynchronously list tuning jobs using the `aio` client.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_74

LANGUAGE: python
CODE:
```
async for job in await client.aio.tunings.list(config={'page_size': 10}):
        print(job)
```

----------------------------------------

TITLE: Deleting a Batch Prediction Job
DESCRIPTION: This snippet deletes a batch prediction job using the client's batches.delete method.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_84

LANGUAGE: python
CODE:
```
delete_job = client.batches.delete(name=job.name)
```

----------------------------------------

TITLE: Disabling Automatic Function Calling
DESCRIPTION: This snippet shows how to disable automatic function calling when a Python function is passed as a tool. This allows manual handling of function calls.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_27

LANGUAGE: python
CODE:
```
response = client.models.generate_content(
    model='gemini-2.0-flash-001',
    contents='What is the weather like in Boston?',
    config=types.GenerateContentConfig(
        tools=[get_current_weather],
        automatic_function_calling=types.AutomaticFunctionCallingConfig(
            disable=True
        ),
    ),
)
```

----------------------------------------

TITLE: Asynchronously Listing Tuning Jobs
DESCRIPTION: This snippet asynchronously iterates through a list of tuning jobs using the client's aio.tunings.list method, printing each job. It configures the page size.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_75

LANGUAGE: python
CODE:
```
async for job in await client.aio.tunings.list(config={'page_size': 10}):
    print(job)
```

----------------------------------------

TITLE: Creating a Content instance
DESCRIPTION: Creates a `types.Content` instance with a specified role and parts. This is the canonical way to provide content to the API.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_12

LANGUAGE: python
CODE:
```
contents = types.Content(
  role='user',
  parts=[types.Part.from_text(text='Why is the sky blue?')]
)
```

----------------------------------------

TITLE: Enum Response Schema - JSON (Python)
DESCRIPTION: This code demonstrates how to use an Enum as a response schema with `response_mime_type` set to `application/json`. The model will return one of the enum values as a JSON string (i.e., in quotes).
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_36

LANGUAGE: python
CODE:
```
from enum import Enum

class InstrumentEnum(Enum):
  PERCUSSION = 'Percussion'
  STRING = 'String'
  WOODWIND = 'Woodwind'
  BRASS = 'Brass'
  KEYBOARD = 'Keyboard'

response = client.models.generate_content(
      model='gemini-2.0-flash-001',
      contents='What instrument plays multiple notes at once?',
      config={
          'response_mime_type': 'application/json',
          'response_schema': InstrumentEnum,
      },
  )
print(response.text)
```

----------------------------------------

TITLE: Monitoring Batch Prediction Job Status in Python
DESCRIPTION: This code snippet demonstrates how to monitor the status of a batch prediction job. It retrieves the job status and waits until the job completes.
SOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#_snippet_78

LANGUAGE: python
CODE:
```
completed_states = set(
        [
            'JOB_STATE_SUCCEEDED',
            'JOB_STATE_FAILED',
            'JOB_STATE_CANCELLED',
            'JOB_STATE_PAUSED',
        ]
    )

    while job.state not in completed_states:
        print(job.state)
        job = client.batches.get(name=job.name)
        time.sleep(30)

    job
```

----------------------------------------

TITLE: Providing a string as content
DESCRIPTION: Demonstrates how a string is automatically converted to a `types.UserContent` instance by the SDK. This simplifies providing text input for content generation.
SOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#_snippet_13

LANGUAGE: python
CODE:
```
contents='Why is the sky blue?'
```