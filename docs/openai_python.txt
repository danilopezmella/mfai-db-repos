TITLE: Installing the OpenAI Python library with pip
DESCRIPTION: Command to install the OpenAI Python library from PyPI using pip. This is the standard way to add the library to your Python environment.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_0

LANGUAGE: sh
CODE:
```
# install from PyPI
pip install openai
```

----------------------------------------

TITLE: Accessing Request IDs in OpenAI Python SDK
DESCRIPTION: Shows how to access request IDs from successful responses and from API error objects for debugging and reporting issues to OpenAI.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_17

LANGUAGE: python
CODE:
```
response = await client.responses.create(
    model="gpt-4o-mini",
    input="Say 'this is a test'.",
)
print(response._request_id)  # req_123
```

LANGUAGE: python
CODE:
```
import openai

try:
    completion = await client.chat.completions.create(
        messages=[{"role": "user", "content": "Say this is a test"}], model="gpt-4"
    )
except openai.APIStatusError as exc:
    print(exc.request_id)  # req_123
    raise exc
```

----------------------------------------

TITLE: Using the Chat Completions API with OpenAI
DESCRIPTION: Example of using the traditional Chat Completions API to generate text from an OpenAI model. It creates a client and sends a chat completion request with role-based messages.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_2

LANGUAGE: python
CODE:
```
from openai import OpenAI

client = OpenAI()

completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "developer", "content": "Talk like a pirate."},
        {
            "role": "user",
            "content": "How do I check if a Python object is an instance of a class?",
        },
    ],
)

print(completion.choices[0].message.content)
```

----------------------------------------

TITLE: Handling Errors in OpenAI Python SDK
DESCRIPTION: Demonstrates error handling with try-except blocks for various API errors including connection issues and different status codes returned by the OpenAI API.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_16

LANGUAGE: python
CODE:
```
import openai
from openai import OpenAI

client = OpenAI()

try:
    client.fine_tuning.jobs.create(
        model="gpt-4o",
        training_file="file-abc123",
    )
except openai.APIConnectionError as e:
    print("The server could not be reached")
    print(e.__cause__)  # an underlying Exception, likely raised within httpx.
except openai.RateLimitError as e:
    print("A 429 status code was received; we should back off a bit.")
except openai.APIStatusError as e:
    print("Another non-200-range status code was received")
    print(e.status_code)
    print(e.response)
```

----------------------------------------

TITLE: Function Tool Calls with Pydantic Models
DESCRIPTION: Shows how to use Pydantic models for automatic parsing of function tool calls. The example implements a database query builder with strict schema validation.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_1

LANGUAGE: python
CODE:
```
from enum import Enum
from typing import List, Union
from pydantic import BaseModel
import openai

class Table(str, Enum):
    orders = "orders"
    customers = "customers"
    products = "products"

class Column(str, Enum):
    id = "id"
    status = "status"
    expected_delivery_date = "expected_delivery_date"
    delivered_at = "delivered_at"
    shipped_at = "shipped_at"
    ordered_at = "ordered_at"
    canceled_at = "canceled_at"

class Operator(str, Enum):
    eq = "="
    gt = ">"
    lt = "<"
    le = "<="
    ge = ">="
    ne = "!="

class OrderBy(str, Enum):
    asc = "asc"
    desc = "desc"

class DynamicValue(BaseModel):
    column_name: str

class Condition(BaseModel):
    column: str
    operator: Operator
    value: Union[str, int, DynamicValue]

class Query(BaseModel):
    table_name: Table
    columns: List[Column]
    conditions: List[Condition]
    order_by: OrderBy

client = openai.OpenAI()
completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant. The current date is August 6, 2024. You help users query for the data they are looking for by calling the query function.",
        },
        {
            "role": "user",
            "content": "look up all my orders in may of last year that were fulfilled but not delivered on time",
        },
    ],
    tools=[
        openai.pydantic_function_tool(Query),
    ],
)

tool_call = (completion.choices[0].message.tool_calls or [])[0]
print(tool_call.function)
assert isinstance(tool_call.function.parsed_arguments, Query)
print(tool_call.function.parsed_arguments.table_name)
```

----------------------------------------

TITLE: Processing images with Vision API using base64 encoding
DESCRIPTION: Example of using the Vision capabilities with a locally stored image. The code reads an image file, converts it to a base64 encoded string, and sends it to the model along with a text prompt.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_4

LANGUAGE: python
CODE:
```
import base64
from openai import OpenAI

client = OpenAI()

prompt = "What is in this image?"
with open("path/to/image.png", "rb") as image_file:
    b64_image = base64.b64encode(image_file.read()).decode("utf-8")

response = client.responses.create(
    model="gpt-4o-mini",
    input=[
        {
            "role": "user",
            "content": [
                {"type": "input_text", "text": prompt},
                {"type": "input_image", "image_url": f"data:image/png;base64,{b64_image}"},
            ],
        }
    ],
)
```

----------------------------------------

TITLE: Pydantic Model Parsing with OpenAI Chat Completions
DESCRIPTION: Demonstrates how to use Pydantic models to automatically parse structured outputs from OpenAI chat completions. The example shows parsing a math problem solution into a defined data structure.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_0

LANGUAGE: python
CODE:
```
from typing import List
from pydantic import BaseModel
from openai import OpenAI

class Step(BaseModel):
    explanation: str
    output: str

class MathResponse(BaseModel):
    steps: List[Step]
    final_answer: str

client = OpenAI()
completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[
        {"role": "system", "content": "You are a helpful math tutor."},
        {"role": "user", "content": "solve 8x + 31 = 2"},
    ],
    response_format=MathResponse,
)

message = completion.choices[0].message
if message.parsed:
    print(message.parsed.steps)
    print("answer: ", message.parsed.final_answer)
else:
    print(message.refusal)
```

----------------------------------------

TITLE: Processing images with Vision API using URL
DESCRIPTION: Example of using the Vision capabilities to analyze an image from a URL. The code sends both text prompt and image URL to the model to get a description of the image content.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_3

LANGUAGE: python
CODE:
```
prompt = "What is in this image?"
img_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/2023_06_08_Raccoon1.jpg/1599px-2023_06_08_Raccoon1.jpg"

response = client.responses.create(
    model="gpt-4o-mini",
    input=[
        {
            "role": "user",
            "content": [
                {"type": "input_text", "text": prompt},
                {"type": "input_image", "image_url": f"{img_url}"},
            ],
        }
    ],
)
```

----------------------------------------

TITLE: Streaming responses with AsyncOpenAI
DESCRIPTION: Example of streaming responses using the asynchronous client. It demonstrates how to create an async stream and process events in an asynchronous context.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_7

LANGUAGE: python
CODE:
```
import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI()


async def main():
    stream = client.responses.create(
        model="gpt-4o",
        input="Write a one-sentence bedtime story about a unicorn.",
        stream=True,
    )

    for event in stream:
        print(event)


asyncio.run(main())
```

----------------------------------------

TITLE: Async Streaming with OpenAI Chat Completions
DESCRIPTION: Demonstrates how to use the async streaming API for chat completions. Shows usage of the context manager and event handling for streamed responses.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_2

LANGUAGE: python
CODE:
```
from openai import AsyncOpenAI

client = AsyncOpenAI()

async with client.beta.chat.completions.stream(
    model='gpt-4o-2024-08-06',
    messages=[...],
) as stream:
    async for event in stream:
        if event.type == 'content.delta':
            print(event.content, flush=True, end='')
```

----------------------------------------

TITLE: Using the AsyncOpenAI client for asynchronous operations
DESCRIPTION: Example of using the AsyncOpenAI client for asynchronous operations. It imports the AsyncOpenAI class, creates an async client, and demonstrates how to use it with async/await syntax.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_5

LANGUAGE: python
CODE:
```
import os
import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI(
    # This is the default and can be omitted
    api_key=os.environ.get("OPENAI_API_KEY"),
)


async def main() -> None:
    response = await client.responses.create(
        model="gpt-4o", input="Explain disestablishmentarianism to a smart five year old."
    )
    print(response.output_text)


asyncio.run(main())
```

----------------------------------------

TITLE: Iterating Over Events in OpenAI Assistant API Stream
DESCRIPTION: This example shows how to iterate over all streamed events from an Assistant run, specifically printing text from text delta events.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_4

LANGUAGE: python
CODE:
```
with client.beta.threads.runs.stream(
  thread_id=thread.id,
  assistant_id=assistant.id
) as stream:
    for event in stream:
        # Print the text from text delta events
        if event.event == "thread.message.delta" and event.data.delta.content:
            print(event.data.delta.content[0].text)
```

----------------------------------------

TITLE: Creating Streams with OpenAI Python SDK
DESCRIPTION: This section shows three helper methods for creating streams: streaming an existing run, creating a thread with a message and streaming the run, and submitting tool outputs to a run and streaming the response.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_6

LANGUAGE: python
CODE:
```
client.beta.threads.runs.stream()
```

LANGUAGE: python
CODE:
```
client.beta.threads.create_and_run_stream()
```

LANGUAGE: python
CODE:
```
client.beta.threads.runs.submit_tool_outputs_stream()
```

----------------------------------------

TITLE: Configuring Retries in OpenAI Python SDK
DESCRIPTION: Demonstrates how to configure retry behavior globally or per-request, either disabling retries or increasing the maximum number of retries.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_18

LANGUAGE: python
CODE:
```
from openai import OpenAI

# Configure the default for all requests:
client = OpenAI(
    # default is 2
    max_retries=0,
)

# Or, configure per-request:
client.with_options(max_retries=5).chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How can I get the name of the current day in JavaScript?",
        }
    ],
    model="gpt-4o",
)
```

----------------------------------------

TITLE: Streaming responses with OpenAI
DESCRIPTION: Example of streaming responses using Server Side Events (SSE). The code creates a stream and iterates through events as they arrive, providing real-time access to model outputs.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_6

LANGUAGE: python
CODE:
```
from openai import OpenAI

client = OpenAI()

stream = client.responses.create(
    model="gpt-4o",
    input="Write a one-sentence bedtime story about a unicorn.",
    stream=True,
)

for event in stream:
    print(event)
```

----------------------------------------

TITLE: Setting Timeouts in OpenAI Python SDK
DESCRIPTION: Shows how to configure request timeouts globally or per-request, including examples of simple timeout values and more granular timeout control.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_19

LANGUAGE: python
CODE:
```
from openai import OpenAI

# Configure the default for all requests:
client = OpenAI(
    # 20 seconds (default is 10 minutes)
    timeout=20.0,
)

# More granular control:
client = OpenAI(
    timeout=httpx.Timeout(60.0, read=5.0, write=10.0, connect=2.0),
)

# Override per-request:
client.with_options(timeout=5.0).chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "How can I list all files in a directory using Python?",
        }
    ],
    model="gpt-4o",
)
```

----------------------------------------

TITLE: Streaming Responses in OpenAI Python SDK
DESCRIPTION: Shows how to stream response data using the with_streaming_response method in a context manager to efficiently process large responses.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_22

LANGUAGE: python
CODE:
```
with client.chat.completions.with_streaming_response.create(
    messages=[
        {
            "role": "user",
            "content": "Say this is a test",
        }
    ],
    model="gpt-4o",
) as response:
    print(response.headers.get("X-My-Header"))

    for line in response.iter_lines():
        print(line)
```

----------------------------------------

TITLE: Creating a Run and Subscribing to Events with Python OpenAI SDK
DESCRIPTION: This snippet demonstrates how to create an event handler class and use it to stream responses from an Assistant run. It shows how to handle different types of events such as text creation, text delta, and tool calls.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_3

LANGUAGE: python
CODE:
```
from typing_extensions import override
from openai import AssistantEventHandler, OpenAI
from openai.types.beta.threads import Text, TextDelta
from openai.types.beta.threads.runs import ToolCall, ToolCallDelta

client = openai.OpenAI()

# First, we create a EventHandler class to define
# how we want to handle the events in the response stream.

class EventHandler(AssistantEventHandler):
  @override
  def on_text_created(self, text: Text) -> None:
    print(f"\nassistant > ", end="", flush=True)

  @override
  def on_text_delta(self, delta: TextDelta, snapshot: Text):
    print(delta.value, end="", flush=True)

  @override
  def on_tool_call_created(self, tool_call: ToolCall):
    print(f"\nassistant > {tool_call.type}\n", flush=True)

  @override
  def on_tool_call_delta(self, delta: ToolCallDelta, snapshot: ToolCall):
    if delta.type == "code_interpreter" and delta.code_interpreter:
      if delta.code_interpreter.input:
        print(delta.code_interpreter.input, end="", flush=True)
      if delta.code_interpreter.outputs:
        print(f"\n\noutput >", flush=True)
        for output in delta.code_interpreter.outputs:
          if output.type == "logs":
            print(f"\n{output.logs}", flush=True)

# Then, we use the `stream` SDK helper
# with the `EventHandler` class to create the Run
# and stream the response.

with client.beta.threads.runs.stream(
  thread_id="thread_id",
  assistant_id="assistant_id",
  event_handler=EventHandler(),
) as stream:
  stream.until_done()
```

----------------------------------------

TITLE: Pagination with the OpenAI API using auto-pagination
DESCRIPTION: Example of using auto-pagination with the OpenAI API. The code iterates through all items across multiple pages, automatically fetching more pages as needed without manual pagination handling.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_10

LANGUAGE: python
CODE:
```
from openai import OpenAI

client = OpenAI()

all_jobs = []
# Automatically fetches more pages as needed.
for job in client.fine_tuning.jobs.list(
    limit=20,
):
    # Do something with job here
    all_jobs.append(job)
print(all_jobs)
```

----------------------------------------

TITLE: Asynchronous pagination with the OpenAI API
DESCRIPTION: Example of using asynchronous auto-pagination with the OpenAI API. It demonstrates how to iterate through paginated results asynchronously using async for, automatically fetching more pages as needed.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_11

LANGUAGE: python
CODE:
```
import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI()


async def main() -> None:
    all_jobs = []
    # Iterate through items across all pages, issuing requests as needed.
    async for job in client.fine_tuning.jobs.list(
        limit=20,
    ):
        all_jobs.append(job)
    print(all_jobs)


asyncio.run(main())
```

----------------------------------------

TITLE: Uploading Files with OpenAI Python SDK
DESCRIPTION: Shows how to upload files to the OpenAI API using Path objects, bytes, or tuples of filename, contents, and media type.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_15

LANGUAGE: python
CODE:
```
from pathlib import Path
from openai import OpenAI

client = OpenAI()

client.files.create(
    file=Path("input.jsonl"),
    purpose="fine-tune",
)
```

----------------------------------------

TITLE: Using the Realtime API for text-based conversations
DESCRIPTION: Example of using the beta Realtime API for text-based conversations. It establishes a WebSocket connection, updates the session to use text modality, and processes events in real-time as they arrive from the server.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_8

LANGUAGE: python
CODE:
```
import asyncio
from openai import AsyncOpenAI

async def main():
    client = AsyncOpenAI()

    async with client.beta.realtime.connect(model="gpt-4o-realtime-preview") as connection:
        await connection.session.update(session={'modalities': ['text']})

        await connection.conversation.item.create(
            item={
                "type": "message",
                "role": "user",
                "content": [{"type": "input_text", "text": "Say hello!"}],
            }
        )
        await connection.response.create()

        async for event in connection:
            if event.type == 'response.text.delta':
                print(event.delta, flush=True, end="")

            elif event.type == 'response.text.done':
                print()

            elif event.type == "response.done":
                break

asyncio.run(main())
```

----------------------------------------

TITLE: Configuring Azure OpenAI Client for API Interaction
DESCRIPTION: Demonstrates how to set up and use the AzureOpenAI client to interact with Azure's OpenAI service. Includes setting the API version, endpoint, and creating a chat completion with a deployment model.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_27

LANGUAGE: python
CODE:
```
from openai import AzureOpenAI

# gets the API Key from environment variable AZURE_OPENAI_API_KEY
client = AzureOpenAI(
    # https://learn.microsoft.com/azure/ai-services/openai/reference#rest-api-versioning
    api_version="2023-07-01-preview",
    # https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource
    azure_endpoint="https://example-endpoint.openai.azure.com",
)

completion = client.chat.completions.create(
    model="deployment-name",  # e.g. gpt-35-instant
    messages=[
        {
            "role": "user",
            "content": "How do I output all files in a directory using Python?",
        },
    ],
)
print(completion.to_json())
```

----------------------------------------

TITLE: Manual pagination control with the OpenAI API
DESCRIPTION: Example of manual pagination control with the OpenAI API. It demonstrates how to check if more pages exist, get information about the next page, and fetch the next page explicitly.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_12

LANGUAGE: python
CODE:
```
first_page = await client.fine_tuning.jobs.list(
    limit=20,
)
if first_page.has_next_page():
    print(f"will fetch next page using these details: {first_page.next_page_info()}")
    next_page = await first_page.get_next_page()
    print(f"number of items we just fetched: {len(next_page.data)}")

# Remove `await` for non-async usage.
```

----------------------------------------

TITLE: Polling Helpers in OpenAI Python SDK
DESCRIPTION: This section lists polling helper methods available in the SDK for handling asynchronous actions like starting a Run or adding files to vector stores. These methods poll the status until it reaches a terminal state and return the resulting object.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_9

LANGUAGE: python
CODE:
```
client.beta.threads.create_and_run_poll(...)
client.beta.threads.runs.create_and_poll(...)
client.beta.threads.runs.submit_tool_outputs_and_poll(...)
client.beta.vector_stores.files.upload_and_poll(...)
client.beta.vector_stores.files.create_and_poll(...)
client.beta.vector_stores.file_batches.create_and_poll(...)
client.beta.vector_stores.file_batches.upload_and_poll(...)
```

----------------------------------------

TITLE: Importing OpenAI Shared Types in Python
DESCRIPTION: Imports common type definitions used across multiple OpenAI API services, including models, filters, function definitions, and response format specifications.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_0

LANGUAGE: python
CODE:
```
from openai.types import (
    AllModels,
    ChatModel,
    ComparisonFilter,
    CompoundFilter,
    ErrorObject,
    FunctionDefinition,
    FunctionParameters,
    Metadata,
    Reasoning,
    ReasoningEffort,
    ResponseFormatJSONObject,
    ResponseFormatJSONSchema,
    ResponseFormatText,
    ResponsesModel,
)
```

----------------------------------------

TITLE: Managing HTTP Resources with Context Manager in OpenAI Python Client
DESCRIPTION: Shows how to properly manage HTTP resources in the OpenAI client using Python's context manager pattern. This ensures connections are properly closed when operations are completed.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_26

LANGUAGE: python
CODE:
```
from openai import OpenAI

with OpenAI() as client:
  # make requests here
  ...

# HTTP client is now closed
```

----------------------------------------

TITLE: Configuring HTTP Client with Custom Proxy and Transport in OpenAI Python Client
DESCRIPTION: Shows how to configure the OpenAI client with a custom HTTP client using httpx. This example demonstrates setting a custom base URL, proxy, and transport configuration for specialized networking requirements.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_24

LANGUAGE: python
CODE:
```
import httpx
from openai import OpenAI, DefaultHttpxClient

client = OpenAI(
    # Or use the `OPENAI_BASE_URL` env var
    base_url="http://my.test.server.example.com:8083/v1",
    http_client=DefaultHttpxClient(
        proxy="http://my.test.proxy.example.com",
        transport=httpx.HTTPTransport(local_address="0.0.0.0"),
    ),
)
```

----------------------------------------

TITLE: Importing Chat Completion Types in Python
DESCRIPTION: Imports comprehensive type definitions for the Chat Completions API, including message types, content parts, tool calls, and response formats for different chat interaction patterns.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_3

LANGUAGE: python
CODE:
```
from openai.types.chat import (
    ChatCompletion,
    ChatCompletionAssistantMessageParam,
    ChatCompletionAudio,
    ChatCompletionAudioParam,
    ChatCompletionChunk,
    ChatCompletionContentPart,
    ChatCompletionContentPartImage,
    ChatCompletionContentPartInputAudio,
    ChatCompletionContentPartRefusal,
    ChatCompletionContentPartText,
    ChatCompletionDeleted,
    ChatCompletionDeveloperMessageParam,
    ChatCompletionFunctionCallOption,
    ChatCompletionFunctionMessageParam,
    ChatCompletionMessage,
    ChatCompletionMessageParam,
    ChatCompletionMessageToolCall,
    ChatCompletionModality,
    ChatCompletionNamedToolChoice,
    ChatCompletionPredictionContent,
    ChatCompletionRole,
    ChatCompletionStoreMessage,
    ChatCompletionStreamOptions,
    ChatCompletionSystemMessageParam,
    ChatCompletionTokenLogprob,
    ChatCompletionTool,
    ChatCompletionToolChoiceOption,
    ChatCompletionToolMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionReasoningEffort,
)
```

----------------------------------------

TITLE: Working directly with paginated data in OpenAI API
DESCRIPTION: Example of working directly with paginated data in the OpenAI API. It shows how to access the cursor for the next page and iterate through the current page's data items.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_13

LANGUAGE: python
CODE:
```
first_page = await client.fine_tuning.jobs.list(
    limit=20,
)

print(f"next page cursor: {first_page.after}")  # => "next page cursor: ..."
for job in first_page.data:
    print(job.id)

# Remove `await` for non-async usage.
```

----------------------------------------

TITLE: Making Custom API Requests in OpenAI Python SDK
DESCRIPTION: Demonstrates how to make requests to undocumented endpoints using HTTP verbs directly and how to send extra parameters that might not be covered in the SDK's typed interface.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_23

LANGUAGE: python
CODE:
```
import httpx

response = client.post(
    "/foo",
    cast_to=httpx.Response,
    body={"my_param": True},
)

print(response.headers.get("x-foo"))
```

----------------------------------------

TITLE: Detecting Null vs Missing Fields in OpenAI Python SDK
DESCRIPTION: Shows how to differentiate between explicit null values and missing fields in API responses using the model_fields_set property.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_20

LANGUAGE: python
CODE:
```
if response.my_field is None:
  if 'my_field' not in response.model_fields_set:
    print('Got json like {}, without a "my_field" key present at all.')
  else:
    print('Got json like {"my_field": null}.')
```

----------------------------------------

TITLE: Customizing OpenAI HTTP Client on a Per-Request Basis
DESCRIPTION: Demonstrates how to customize the OpenAI client's HTTP settings for a specific request using the with_options() method, allowing for temporary configuration changes without modifying the base client.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_25

LANGUAGE: python
CODE:
```
client.with_options(http_client=DefaultHttpxClient(...))
```

----------------------------------------

TITLE: Importing Embedding Types in Python
DESCRIPTION: Imports types related to the Embeddings API, which provides vector representations of text for use in machine learning applications and semantic search.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_4

LANGUAGE: python
CODE:
```
from openai.types import CreateEmbeddingResponse, Embedding, EmbeddingModel
```

----------------------------------------

TITLE: Using Nested Parameters with OpenAI Python SDK
DESCRIPTION: Demonstrates how to use nested dictionary parameters with TypedDict in the OpenAI Python SDK to create a chat response with JSON formatting.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_14

LANGUAGE: python
CODE:
```
from openai import OpenAI

client = OpenAI()

response = client.chat.responses.create(
    input=[
        {
            "role": "user",
            "content": "How much ?",
        }
    ],
    model="gpt-4o",
    response_format={"type": "json_object"},
)
```

----------------------------------------

TITLE: Importing Message Types in Python
DESCRIPTION: Import statements for message-related types including annotations, content blocks, and delta events from the OpenAI beta threads module.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_26

LANGUAGE: python
CODE:
```
from openai.types.beta.threads import (
    Annotation,
    AnnotationDelta,
    FileCitationAnnotation,
    FileCitationDeltaAnnotation,
    FilePathAnnotation,
    FilePathDeltaAnnotation,
    ImageFile,
    ImageFileContentBlock,
    ImageFileDelta,
    ImageFileDeltaBlock,
    ImageURL,
    ImageURLContentBlock,
    ImageURLDelta,
    ImageURLDeltaBlock,
    Message,
    MessageContent,
    MessageContentDelta,
    MessageContentPartParam,
    MessageDeleted,
    MessageDelta,
    MessageDeltaEvent,
    RefusalContentBlock,
    RefusalDeltaBlock,
    Text,
    TextContentBlock,
    TextContentBlockParam,
    TextDelta,
    TextDeltaBlock,
)
```

----------------------------------------

TITLE: Accessing Raw Response Data in OpenAI Python SDK
DESCRIPTION: Demonstrates how to access raw HTTP response data including headers by using the with_raw_response method prefix.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_21

LANGUAGE: python
CODE:
```
from openai import OpenAI

client = OpenAI()
response = client.chat.completions.with_raw_response.create(
    messages=[{
        "role": "user",
        "content": "Say this is a test",
    }],
    model="gpt-4o",
)
print(response.headers.get('X-My-Header'))

completion = response.parse()  # get the object that `chat.completions.create()` would have returned
print(completion)
```

----------------------------------------

TITLE: Importing Run Types in Python
DESCRIPTION: Import statements for thread run-related types including RequiredActionFunctionToolCall, Run, and RunStatus from the OpenAI beta threads module.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_24

LANGUAGE: python
CODE:
```
from openai.types.beta.threads import RequiredActionFunctionToolCall, Run, RunStatus
```

----------------------------------------

TITLE: Importing ChatModel Type in Python
DESCRIPTION: Imports the ChatModel type from the OpenAI types module, which represents models specifically designed for chat completion tasks.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_2

LANGUAGE: python
CODE:
```
from openai.types import ChatModel
```

----------------------------------------

TITLE: Importing Run Steps Types in Python
DESCRIPTION: Import statements for various run step related types including tool calls, step details, and delta events from the OpenAI beta threads runs module.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_25

LANGUAGE: python
CODE:
```
from openai.types.beta.threads.runs import (
    CodeInterpreterLogs,
    CodeInterpreterOutputImage,
    CodeInterpreterToolCall,
    CodeInterpreterToolCallDelta,
    FileSearchToolCall,
    FileSearchToolCallDelta,
    FunctionToolCall,
    FunctionToolCallDelta,
    MessageCreationStepDetails,
    RunStep,
    RunStepDelta,
    RunStepDeltaEvent,
    RunStepDeltaMessageDelta,
    RunStepInclude,
    ToolCall,
    ToolCallDelta,
    ToolCallDeltaObject,
    ToolCallsStepDetails,
)
```

----------------------------------------

TITLE: Importing Beta Assistant Types in Python
DESCRIPTION: This snippet shows how to import various types related to the Beta Assistants API from the OpenAI Python library.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_22

LANGUAGE: python
CODE:
```
from openai.types.beta import (
    Assistant,
    AssistantDeleted,
    AssistantStreamEvent,
    AssistantTool,
    CodeInterpreterTool,
    FileSearchTool,
    FunctionTool,
    MessageStreamEvent,
    RunStepStreamEvent,
    RunStreamEvent,
    ThreadStreamEvent,
)
```

----------------------------------------

TITLE: Importing Beta Thread Types in Python
DESCRIPTION: This snippet demonstrates how to import various types related to the Beta Threads API from the OpenAI Python library.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_23

LANGUAGE: python
CODE:
```
from openai.types.beta import (
    AssistantResponseFormatOption,
    AssistantToolChoice,
    AssistantToolChoiceFunction,
    AssistantToolChoiceOption,
    Thread,
    ThreadDeleted,
)
```

----------------------------------------

TITLE: Importing Audio Model Types in Python
DESCRIPTION: Imports core audio-related types for OpenAI's audio processing capabilities, including model specifications and response format options.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_7

LANGUAGE: python
CODE:
```
from openai.types import AudioModel, AudioResponseFormat
```

----------------------------------------

TITLE: Importing Speech Synthesis Model Type in Python
DESCRIPTION: Imports the SpeechModel type for the Speech API, which is used for text-to-speech synthesis capabilities.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_10

LANGUAGE: python
CODE:
```
from openai.types.audio import SpeechModel
```

----------------------------------------

TITLE: Iterating Over Text Deltas in OpenAI Assistant API Stream
DESCRIPTION: This snippet demonstrates how to iterate specifically over text deltas received from an Assistant run stream.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_5

LANGUAGE: python
CODE:
```
with client.beta.threads.runs.stream(
  thread_id=thread.id,
  assistant_id=assistant.id
) as stream:
    for text in stream.text_deltas:
        print(text)
```

----------------------------------------

TITLE: Assistant Methods in OpenAI Python SDK
DESCRIPTION: This section lists convenience methods provided by the assistant streaming object, including methods to access current context and methods to get final run information.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_8

LANGUAGE: python
CODE:
```
def current_event() -> AssistantStreamEvent | None
def current_run() -> Run | None
def current_message_snapshot() -> Message | None
def current_run_step_snapshot() -> RunStep | None
```

LANGUAGE: python
CODE:
```
def get_final_run(self) -> Run
def get_final_run_steps(self) -> List[RunStep]
def get_final_messages(self) -> List[Message]
```

----------------------------------------

TITLE: Importing Audio Translation Types in Python
DESCRIPTION: Imports types for the Audio Translations API, which translates speech from one language to text in another language, with support for verbose output.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_9

LANGUAGE: python
CODE:
```
from openai.types.audio import Translation, TranslationVerbose, TranslationCreateResponse
```

----------------------------------------

TITLE: Assistant Events in OpenAI Python SDK
DESCRIPTION: This section lists various event handlers available in the Assistant API, including general events, run step events, message events, text events, image file events, tool call events, and special events like stream end, timeout, and exceptions.
SOURCE: https://github.com/openai/openai-python/blob/main/helpers.md#2025-04-23_snippet_7

LANGUAGE: python
CODE:
```
def on_event(self, event: AssistantStreamEvent)
```

LANGUAGE: python
CODE:
```
def on_run_step_created(self, run_step: RunStep)
def on_run_step_delta(self, delta: RunStepDelta, snapshot: RunStep)
def on_run_step_done(self, run_step: RunStep)
```

LANGUAGE: python
CODE:
```
def on_message_created(self, message: Message)
def on_message_delta(self, delta: MessageDelta, snapshot: Message)
def on_message_done(self, message: Message)
```

LANGUAGE: python
CODE:
```
def on_text_created(self, text: Text)
def on_text_delta(self, delta: TextDelta, snapshot: Text)
def on_text_done(self, text: Text)
```

LANGUAGE: python
CODE:
```
def on_image_file_done(self, image_file: ImageFile)
```

LANGUAGE: python
CODE:
```
def on_tool_call_created(self, tool_call: ToolCall)
def on_tool_call_delta(self, delta: ToolCallDelta, snapshot: ToolCall)
def on_tool_call_done(self, tool_call: ToolCall)
```

LANGUAGE: python
CODE:
```
def on_end(self)
```

LANGUAGE: python
CODE:
```
def on_timeout(self)
```

LANGUAGE: python
CODE:
```
def on_exception(self, exception: Exception)
```

----------------------------------------

TITLE: Importing Realtime Types in Python
DESCRIPTION: This snippet demonstrates how to import various types related to the Realtime API from the OpenAI Python library.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_19

LANGUAGE: python
CODE:
```
from openai.types.beta.realtime import (
    ConversationCreatedEvent,
    ConversationItem,
    ConversationItemContent,
    ConversationItemCreateEvent,
    ConversationItemCreatedEvent,
    ConversationItemDeleteEvent,
    ConversationItemDeletedEvent,
    ConversationItemInputAudioTranscriptionCompletedEvent,
    ConversationItemInputAudioTranscriptionDeltaEvent,
    ConversationItemInputAudioTranscriptionFailedEvent,
    ConversationItemRetrieveEvent,
    ConversationItemTruncateEvent,
    ConversationItemTruncatedEvent,
    ConversationItemWithReference,
    ErrorEvent,
    InputAudioBufferAppendEvent,
    InputAudioBufferClearEvent,
    InputAudioBufferClearedEvent,
    InputAudioBufferCommitEvent,
    InputAudioBufferCommittedEvent,
    InputAudioBufferSpeechStartedEvent,
    InputAudioBufferSpeechStoppedEvent,
    RateLimitsUpdatedEvent,
    RealtimeClientEvent,
    RealtimeResponse,
    RealtimeResponseStatus,
    RealtimeResponseUsage,
    RealtimeServerEvent,
    ResponseAudioDeltaEvent,
    ResponseAudioDoneEvent,
    ResponseAudioTranscriptDeltaEvent,
    ResponseAudioTranscriptDoneEvent,
    ResponseCancelEvent,
    ResponseContentPartAddedEvent,
    ResponseContentPartDoneEvent,
    ResponseCreateEvent,
    ResponseCreatedEvent,
    ResponseDoneEvent,
    ResponseFunctionCallArgumentsDeltaEvent,
    ResponseFunctionCallArgumentsDoneEvent,
    ResponseOutputItemAddedEvent,
    ResponseOutputItemDoneEvent,
    ResponseTextDeltaEvent,
    ResponseTextDoneEvent,
    SessionCreatedEvent,
    SessionUpdateEvent,
    SessionUpdatedEvent,
    TranscriptionSessionUpdate,
    TranscriptionSessionUpdatedEvent,
)
```

----------------------------------------

TITLE: Importing Vector Store Types in Python
DESCRIPTION: Imports the types needed for vector store operations, including file chunking strategies and vector store operation responses.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_16

LANGUAGE: python
CODE:
```
from openai.types import (
    AutoFileChunkingStrategyParam,
    FileChunkingStrategy,
    FileChunkingStrategyParam,
    OtherFileChunkingStrategyObject,
    StaticFileChunkingStrategy,
    StaticFileChunkingStrategyObject,
    StaticFileChunkingStrategyObjectParam,
    VectorStore,
    VectorStoreDeleted,
    VectorStoreSearchResponse,
)
```

----------------------------------------

TITLE: Importing Vector Store File Types in Python
DESCRIPTION: Imports types for working with files in vector stores, including file operations responses and content retrieval.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_17

LANGUAGE: python
CODE:
```
from openai.types.vector_stores import VectorStoreFile, VectorStoreFileDeleted, FileContentResponse
```

----------------------------------------

TITLE: Importing FileBatches Types in Python
DESCRIPTION: This snippet shows how to import the VectorStoreFileBatch type from the OpenAI Python library.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_18

LANGUAGE: python
CODE:
```
from openai.types.vector_stores import VectorStoreFileBatch
```

----------------------------------------

TITLE: Importing Completion Types in Python
DESCRIPTION: Imports type definitions specific to the Completions API, including the main Completion type and related choice and usage statistics types.
SOURCE: https://github.com/openai/openai-python/blob/main/api.md#2025-04-23_snippet_1

LANGUAGE: python
CODE:
```
from openai.types import Completion, CompletionChoice, CompletionUsage
```

----------------------------------------

TITLE: Determining Installed OpenAI Library Version
DESCRIPTION: Shows how to check which version of the OpenAI Python library is currently installed and being used at runtime, which is useful for debugging and ensuring compatibility.
SOURCE: https://github.com/openai/openai-python/blob/main/README.md#2025-04-23_snippet_28

LANGUAGE: python
CODE:
```
import openai
print(openai.__version__)
```